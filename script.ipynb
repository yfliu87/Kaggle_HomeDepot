{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorIndexer,VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator,MulticlassClassificationEvaluator\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local\") \\\n",
    "            .appName(\"kaggle\") \\\n",
    "            .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/final.prediction\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"127.0.0.1\",27017,maxPoolSize=10000)\n",
    "outputCollection = client['final']['prediction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prd_train_raw = client['final']['train']\n",
    "prd_train = []\n",
    "for document in prd_train_raw.find({}):\n",
    "    prd_train.append((int(document['id']),int(document['product_uid']), document['product_title'], \\\n",
    "                      str(document['search_term']), float(document['relevance'])))\n",
    "\n",
    "# define schema for training data\n",
    "training_schema = StructType([\n",
    "        StructField(\"id\", IntegerType(), False),\n",
    "        StructField(\"product_uid\", IntegerType(), False),\n",
    "        StructField(\"product_title\", StringType(), False),\n",
    "        StructField(\"search_term\", StringType(), False),\n",
    "        StructField(\"relevance\", DoubleType(), False),\n",
    "    ])\n",
    "\n",
    "training_rdd = sc.parallelize(prd_train)\n",
    "training_df = spark.createDataFrame(training_rdd, training_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|         relevance|\n",
      "+-------+------------------+\n",
      "|  count|             74067|\n",
      "|   mean|2.3816337910269922|\n",
      "| stddev|0.5339839484172036|\n",
      "|    min|               1.0|\n",
      "|    max|               3.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.describe(['relevance']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|relevance|count|\n",
      "+---------+-----+\n",
      "|      3.0|19125|\n",
      "|     2.33|16060|\n",
      "|     2.67|15202|\n",
      "|      2.0|11730|\n",
      "|     1.67| 6780|\n",
      "|     1.33| 3006|\n",
      "|      1.0| 2105|\n",
      "|      2.5|   19|\n",
      "|     2.75|   11|\n",
      "|     2.25|   11|\n",
      "|     1.75|    9|\n",
      "|      1.5|    5|\n",
      "|     1.25|    4|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.cube('relevance').count().dropna().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|round(relevance, 0)|count|\n",
      "+-------------------+-----+\n",
      "|                2.0|34595|\n",
      "|                3.0|34357|\n",
      "|                1.0| 5115|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the label imbalance\n",
    "training_df.cube(round('relevance')).count().dropna().orderBy('count', ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read test data from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prd_test_raw = client['final']['test']\n",
    "prd_test = []\n",
    "for document in prd_test_raw.find({}):\n",
    "    prd_test.append((int(document['id']), int(document['product_uid']), \\\n",
    "                     document['product_title'], str(document['search_term'])))\n",
    "\n",
    "# define schema for test\n",
    "test_schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), False),\n",
    "    StructField(\"product_uid\", IntegerType(), False),\n",
    "    StructField(\"product_title\", StringType(), False),\n",
    "    StructField(\"search_term\", StringType(), False),\n",
    "    ])\n",
    "\n",
    "test_rdd = sc.parallelize(prd_test)\n",
    "test_df = spark.createDataFrame(test_rdd, test_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read product description from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prd_description_raw = client['final']['product_description']\n",
    "prd_description = []\n",
    "\n",
    "for document in prd_description_raw.find({}):\n",
    "    prd_description.append((int(document['product_uid']), str(document['product_description'])))  \n",
    "    \n",
    "# define schema for product_description\",\n",
    "prd_schema = StructType([\n",
    "    StructField(\"product_uid\",IntegerType(), False),\n",
    "    StructField(\"product_description\", StringType(), True),\n",
    "])\n",
    "\n",
    "prd_rdd = sc.parallelize(prd_description)\n",
    "prd_df = spark.createDataFrame(prd_rdd, prd_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF tokenize method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "english_punctuations = [',','.',':',';','?','!','(',')','&','#','%']\n",
    "lmtz = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokenizedWords = [word for word in word_tokenize(text.strip())]\n",
    "    \n",
    "    # remove stop words\n",
    "    filteredWords = [word for word in tokenizedWords if word not in english_stopwords]\n",
    "\n",
    "    # remove punctuations\n",
    "    filtered = [word for word in filteredWords if word not in english_punctuations]\n",
    "    \n",
    "    # lemmatize word\n",
    "    lemmatized = [lmtz.lemmatize(word) for word in filtered]\n",
    "    \n",
    "    return ','.join(lemmatized)\n",
    "\n",
    "# define tokenizer\n",
    "udfTokenize = udf(tokenizer, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_uid: int, id: int, product_title: string, search_term: string, relevance: double, product_description: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join training data with product description\n",
    "training_full_df = training_df.join(prd_df, 'product_uid', \"left_outer\")\n",
    "training_full_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, tokenized_title: string, tokenized_description: string, tokenized_search: string, relevance: double]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert product_title & product_description to lower case\n",
    "training_preprocessedDF = training_full_df.select('id','product_uid', lower(training_full_df.product_title), \\\n",
    "                                                 lower(training_full_df.product_description), \\\n",
    "                                                 lower(training_full_df.search_term), 'relevance') \\\n",
    "                                   .withColumn(\"tokenized_title\", udfTokenize(\"lower(product_title)\")) \\\n",
    "                                   .withColumn(\"tokenized_description\", udfTokenize(\"lower(product_description)\")) \\\n",
    "                                   .withColumn(\"tokenized_search\", udfTokenize(\"lower(search_term)\")) \\\n",
    "                                   .select('id','product_uid','tokenized_title','tokenized_description','tokenized_search','relevance')\n",
    "\n",
    "training_preprocessedDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split training & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_prepDF, validation_prepDF = training_preprocessedDF.randomSplit([0.8,0.2], seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product_uid: int, id: int, product_title: string, search_term: string, product_description: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_df = test_df.join(prd_df, 'product_uid', \"left_outer\")\n",
    "test_full_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, tokenized_title: string, tokenized_description: string, tokenized_search: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert product_title & product_description to lower case\n",
    "test_prepDF = test_full_df.select('id', 'product_uid', lower(test_full_df.product_title), \\\n",
    "                                         lower(test_full_df.search_term), lower(test_full_df.product_description)) \\\n",
    "                                 .withColumn(\"tokenized_title\", udfTokenize(\"lower(product_title)\")) \\\n",
    "                                 .withColumn(\"tokenized_description\", udfTokenize(\"lower(product_description)\")) \\\n",
    "                                 .withColumn(\"tokenized_search\", udfTokenize(\"lower(search_term)\")) \\\n",
    "                                 .select('id', 'product_uid', 'tokenized_title','tokenized_description','tokenized_search')\n",
    "test_prepDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity and distance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define ratio of matches between search term and target field\n",
    "def simCalc(src_text, target_text):\n",
    "    src_words = src_text.split(\",\")\n",
    "    target_words = target_text.split(\",\")\n",
    "\n",
    "    # Jaccard similarity\n",
    "    intersection = set(src_words).intersection(set(target_words))\n",
    "    return float(len(intersection))/len(src_words)\n",
    "\n",
    "jaccardSim = udf(simCalc, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define occurrence of matches between search term and target field \n",
    "def simOccur(src_text, target_text):\n",
    "    src_words = src_text.split(\",\")\n",
    "    target_words = target_text.split(\",\")\n",
    "    intersection = set(src_words).intersection(set(target_words))\n",
    "    return len(intersection)\n",
    "\n",
    "occurSim = udf(simOccur, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def applySim(df):\n",
    "    return df.withColumn('title_search_hit_ratio',jaccardSim('tokenized_search','tokenized_title')) \\\n",
    "             .withColumn('title_search_hit_occur', occurSim('tokenized_search','tokenized_title')) \\\n",
    "             .withColumn('desc_search_hit_ratio', jaccardSim('tokenized_search','tokenized_description')) \\\n",
    "             .withColumn('desc_search_hit_occur', occurSim('tokenized_search','tokenized_description'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, title_search_hit_occur: int, title_search_hit_ratio: double, desc_search_hit_occur: int, desc_search_hit_ratio: double, tokenized_search: string, tokenized_title: string, tokenized_description: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the search hit in title field\n",
    "searchHitTrainingDF = applySim(training_prepDF) \\\n",
    "                    .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                            'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                            'tokenized_search','tokenized_title','tokenized_description','relevance')\n",
    "\n",
    "searchHitValidationDF = applySim(validation_prepDF) \\\n",
    "                    .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                            'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                            'tokenized_search','tokenized_title','tokenized_description','relevance')\n",
    "\n",
    "searchHitTestDF = applySim(test_prepDF) \\\n",
    "                        .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                            'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                            'tokenized_search','tokenized_title','tokenized_description')\n",
    "\n",
    "searchHitTrainingDF.cache()\n",
    "searchHitValidationDF.cache()\n",
    "searchHitTestDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, title_search_hit_occur: int, title_search_hit_ratio: double, desc_search_hit_occur: int, desc_search_hit_ratio: double, tokenized_search: string, tokenized_title: string, tokenized_description: string, row_id: bigint]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add row_id for retrieving LDA similar document\n",
    "searchHitTrainingDF_with_row_id = searchHitTrainingDF.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "searchHitTrainingDF_with_row_id.cache()\n",
    "\n",
    "searchHitValidationDF_with_row_id = searchHitValidationDF.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "searchHitValidationDF_with_row_id.cache()\n",
    "\n",
    "searchHitTestDF_with_row_id = searchHitTestDF.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "searchHitTestDF_with_row_id.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "\n",
    "def ldaSim(docs):\n",
    "    # bag of words\n",
    "    dictionary = corpora.Dictionary(docs)\n",
    "    \n",
    "    # map document to (word, frequency)\n",
    "    corpus = [dictionary.doc2bow(text) for text in docs]\n",
    "    \n",
    "    # conver (word,frequency) to tfidf model\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    \n",
    "    # (word,tfidf value)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "    lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=5)\n",
    "    \n",
    "    # create index \n",
    "    index = similarities.MatrixSimilarity(lda[corpus])\n",
    "\n",
    "    return (index, dictionary, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get description field - list operation, memory consuming\n",
    "desc_docs = searchHitTrainingDF_with_row_id.select('tokenized_description').rdd.flatMap(lambda x:x).collect()\n",
    "\n",
    "desc_index, desc_dictionary, desc_lda = ldaSim([doc.split(',') for doc in desc_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define sim\n",
    "def ldaDescSimilarity(q, pid):\n",
    "    # vectorize query terms\n",
    "    query_bow = desc_dictionary.doc2bow(q.lower().split())\n",
    "    \n",
    "    # map query to 2-dimensional space\n",
    "    query_lda = desc_lda[query_bow]\n",
    "    \n",
    "    # get cosine similarity of query with each document\n",
    "    sims = desc_index[query_lda]\n",
    "    \n",
    "    sorted_sims = sorted(enumerate(sims))\n",
    "    \n",
    "    return float(sorted_sims[pid][1]) if pid < len(sorted_sims) else 0.0\n",
    "\n",
    "searchDescLDAsim = udf(ldaDescSimilarity, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get title field - list operation memory consuming\n",
    "title_docs = searchHitTrainingDF_with_row_id.select('tokenized_title').rdd.flatMap(lambda x:x).collect()\n",
    "\n",
    "title_index, title_dictionary, title_lda = ldaSim([doc.split(',') for doc in title_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define sim\n",
    "def ldaTitleSimilarity(q, pid):\n",
    "    sims = title_index[title_lda[title_dictionary.doc2bow(q.split())]]\n",
    "    \n",
    "    sorted_sims = sorted(enumerate(sims))\n",
    "    \n",
    "    return float(sorted_sims[pid][1]) if pid < len(sorted_sims) else 0.0\n",
    "    \n",
    "searchTitleLDAsim = udf(ldaTitleSimilarity, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, title_search_hit_occur: int, title_search_hit_ratio: double, desc_search_hit_occur: int, desc_search_hit_ratio: double, searchTitleLDASim: float, searchDescLDASim: float, relevance: double]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingReadyDF = searchHitTrainingDF_with_row_id \\\n",
    "                .withColumn('searchTitleLDASim', searchTitleLDAsim('tokenized_search','row_id')) \\\n",
    "                .withColumn('searchDescLDASim', searchDescLDAsim('tokenized_search','row_id')) \\\n",
    "                .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                        'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                        'searchTitleLDASim','searchDescLDASim','relevance')\n",
    "trainingReadyDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, title_search_hit_occur: int, title_search_hit_ratio: double, desc_search_hit_occur: int, desc_search_hit_ratio: double, searchTitleLDASim: float, searchDescLDASim: float, relevance: double]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationReadyDF = searchHitValidationDF_with_row_id \\\n",
    "                .withColumn('searchTitleLDASim', searchTitleLDAsim('tokenized_search','row_id')) \\\n",
    "                .withColumn('searchDescLDASim', searchDescLDAsim('tokenized_search','row_id')) \\\n",
    "                .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                        'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                        'searchTitleLDASim','searchDescLDASim','relevance')\n",
    "validationReadyDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, product_uid: int, title_search_hit_occur: int, title_search_hit_ratio: double, desc_search_hit_occur: int, desc_search_hit_ratio: double, searchTitleLDASim: float, searchDescLDASim: float]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testReadyDF = searchHitTestDF_with_row_id \\\n",
    "                .withColumn('searchTitleLDASim', searchTitleLDAsim('tokenized_search','row_id')) \\\n",
    "                .withColumn('searchDescLDASim', searchDescLDAsim('tokenized_search','row_id')) \\\n",
    "                .select('id','product_uid','title_search_hit_occur','title_search_hit_ratio', \\\n",
    "                        'desc_search_hit_occur','desc_search_hit_ratio', \\\n",
    "                        'searchTitleLDASim','searchDescLDASim')\n",
    "testReadyDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema of training & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- product_uid: integer (nullable = false)\n",
      " |-- title_search_hit_occur: integer (nullable = true)\n",
      " |-- title_search_hit_ratio: double (nullable = true)\n",
      " |-- desc_search_hit_occur: integer (nullable = true)\n",
      " |-- desc_search_hit_ratio: double (nullable = true)\n",
      " |-- searchTitleLDASim: float (nullable = true)\n",
      " |-- searchDescLDASim: float (nullable = true)\n",
      " |-- relevance: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- product_uid: integer (nullable = false)\n",
      " |-- title_search_hit_occur: integer (nullable = true)\n",
      " |-- title_search_hit_ratio: double (nullable = true)\n",
      " |-- desc_search_hit_occur: integer (nullable = true)\n",
      " |-- desc_search_hit_ratio: double (nullable = true)\n",
      " |-- searchTitleLDASim: float (nullable = true)\n",
      " |-- searchDescLDASim: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingReadyDF.printSchema()\n",
    "testReadyDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureCols = ['title_search_hit_occur','title_search_hit_ratio','desc_search_hit_occur', \\\n",
    "               'desc_search_hit_ratio','searchTitleLDASim','searchDescLDASim']\n",
    "\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\")\n",
    "\n",
    "training_DF = trainingReadyDF.select(col('title_search_hit_occur'), col('title_search_hit_ratio'), \\\n",
    "                                     col('desc_search_hit_occur'), col('desc_search_hit_ratio'), \\\n",
    "                                     col('searchTitleLDASim'), col('searchDescLDASim'), \\\n",
    "                                     col('relevance').alias('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(featuresCol = 'features', numTrees=20, maxDepth=2)\n",
    "\n",
    "regPipeline = Pipeline(stages = [assembler, regressor])\n",
    "\n",
    "regModel = regPipeline.fit(training_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = false)\n",
      " |-- product_uid: integer (nullable = false)\n",
      " |-- title_search_hit_occur: integer (nullable = true)\n",
      " |-- title_search_hit_ratio: double (nullable = true)\n",
      " |-- desc_search_hit_occur: integer (nullable = true)\n",
      " |-- desc_search_hit_ratio: double (nullable = true)\n",
      " |-- searchTitleLDASim: float (nullable = true)\n",
      " |-- searchDescLDASim: float (nullable = true)\n",
      " |-- relevance: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "0.501531720921\n"
     ]
    }
   ],
   "source": [
    "regValidations = regModel.transform(validationReadyDF)\n",
    "\n",
    "regValidations.printSchema()\n",
    "\n",
    "regEvaluator = RegressionEvaluator(labelCol = \"relevance\", predictionCol = \"prediction\", metricName = \"rmse\")\n",
    "\n",
    "print regEvaluator.evaluate(regValidations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search optimal paramter for regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "                .addGrid(regressor.maxDepth, [2,3,4,5]) \\\n",
    "                .addGrid(regressor.numTrees, [15,20,25]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title_search_hit_occur: integer (nullable = true)\n",
      " |-- title_search_hit_ratio: double (nullable = true)\n",
      " |-- desc_search_hit_occur: integer (nullable = true)\n",
      " |-- desc_search_hit_ratio: double (nullable = true)\n",
      " |-- searchTitleLDASim: float (nullable = true)\n",
      " |-- searchDescLDASim: float (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "regression best tree depth:  5\n",
      "regression best tree num:  20\n"
     ]
    }
   ],
   "source": [
    "regEvaluator = RegressionEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"rmse\")\n",
    "cv = CrossValidator(estimator = regressor, estimatorParamMaps = paramGrid, evaluator = regEvaluator, numFolds = 5)\n",
    "\n",
    "df = Pipeline(stages = [assembler]) \\\n",
    "        .fit(training_DF) \\\n",
    "        .transform(validationReadyDF.select(col('title_search_hit_occur'), col('title_search_hit_ratio'), \\\n",
    "                                     col('desc_search_hit_occur'), col('desc_search_hit_ratio'), \\\n",
    "                                     col('searchTitleLDASim'), col('searchDescLDASim'), \\\n",
    "                                     col('relevance').alias('label')))        \n",
    "df.printSchema()\n",
    "cvModel = cv.fit(df)\n",
    "\n",
    "optimal_tree_depth = cvModel.bestModel.trees[0].depth\n",
    "optimal_tree_num = cvModel.bestModel.getNumTrees\n",
    "print \"regression best tree depth: \", optimal_tree_depth\n",
    "print \"regression best tree num: \", optimal_tree_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict on test set using optimal regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train classifier using optimal parameters\n",
    "optimalReg = RandomForestRegressor(labelCol = \"label\",featuresCol = \"features\", numTrees = optimal_tree_num, maxDepth=optimal_tree_depth)\n",
    "\n",
    "optimalRegPipeline = Pipeline(stages = [assembler, optimalReg])\n",
    "\n",
    "optimalRegPredictions = optimalRegPipeline.fit(training_DF) \\\n",
    "                            .transform(testReadyDF.select(col('id'), col('title_search_hit_occur'), \\\n",
    "                                     col('title_search_hit_ratio'), col('desc_search_hit_occur'), \\\n",
    "                                     col('desc_search_hit_ratio'), col('searchTitleLDASim'), col('searchDescLDASim')))\n",
    "\n",
    "optimalRegPredict = optimalRegPredictions.withColumn('predict', round('prediction')).select('id', 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 166693 prediction results to db\n"
     ]
    }
   ],
   "source": [
    "def formatRow(row):\n",
    "    ret = {}\n",
    "    ret['title'] = 'optimal_regressor'\n",
    "    ret['id'] = int(row[0])\n",
    "    ret['prediction'] = int(row[1])\n",
    "    return ret\n",
    "    \n",
    "l = optimalRegPredict.rdd.map(list).collect()\n",
    "formattedResult = map(formatRow, l)\n",
    "\n",
    "# save prediction result\n",
    "result = outputCollection.insert_many(formattedResult)\n",
    "\n",
    "print \"Inserted %d prediction results to db\" %len(result.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(labelCol = \"label\",featuresCol = \"features\", numTrees = 20)\n",
    "\n",
    "classifierPipeline = Pipeline(stages = [assembler, classifier])\n",
    "\n",
    "classificationModel = classifierPipeline.fit(trainingReadyDF.select('title_search_hit_occur', \\\n",
    "                                     'title_search_hit_ratio', 'desc_search_hit_occur', \\\n",
    "                                     'desc_search_hit_ratio', 'searchTitleLDASim', 'searchDescLDASim', \\\n",
    "                                     round('relevance').alias('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy of classification model:  0.583846309951\n"
     ]
    }
   ],
   "source": [
    "# convert label to [1.0,2.0,3.0] for both training and test set\n",
    "clsPredictions = classificationModel.transform(validationReadyDF.withColumn('label', round('relevance')))\n",
    "\n",
    "clsPredict = clsPredictions.withColumn('predict', round('prediction'))\n",
    "\n",
    "clsEvaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"predict\", metricName = \"accuracy\")\n",
    "\n",
    "print \"accuracy of classification model: \", clsEvaluator.evaluate(clsPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search optimal parameter for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier best tree depth:  5\n",
      "classifier best tree num:  20\n"
     ]
    }
   ],
   "source": [
    "clsEvaluator = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "cv = CrossValidator(estimator = classifier, estimatorParamMaps = paramGrid, evaluator = clsEvaluator, numFolds = 5)\n",
    "\n",
    "trDF = trainingReadyDF.select('title_search_hit_occur', \\\n",
    "                                     'title_search_hit_ratio', 'desc_search_hit_occur', \\\n",
    "                                     'desc_search_hit_ratio', 'searchTitleLDASim', 'searchDescLDASim', \\\n",
    "                                     round('relevance').alias('label')).cache()\n",
    "\n",
    "vrDF = validationReadyDF.select('id', 'title_search_hit_occur', \\\n",
    "                                     'title_search_hit_ratio', 'desc_search_hit_occur', \\\n",
    "                                     'desc_search_hit_ratio', 'searchTitleLDASim', 'searchDescLDASim', \\\n",
    "                                           round('relevance').alias('label')).cache()\n",
    "\n",
    "df = Pipeline(stages = [assembler]).fit(trDF).transform(vrDF)\n",
    "    \n",
    "cvModel = cv.fit(df)\n",
    "\n",
    "optimal_tree_depth = cvModel.bestModel.trees[0].depth\n",
    "optimal_tree_num = cvModel.bestModel.getNumTrees\n",
    "print \"classifier best tree depth: \", optimal_tree_depth\n",
    "print \"classifier best tree num: \", optimal_tree_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction on test set using classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train classifier using optimal parameters\n",
    "optimalCls = RandomForestClassifier(labelCol = \"label\",featuresCol = \"features\", numTrees = optimal_tree_num, maxDepth=optimal_tree_depth)\n",
    "\n",
    "optimalClsPipeline = Pipeline(stages = [assembler, optimalCls])\n",
    "\n",
    "trDF = trainingReadyDF.select('title_search_hit_occur', \\\n",
    "                                     'title_search_hit_ratio', 'desc_search_hit_occur', \\\n",
    "                                     'desc_search_hit_ratio', 'searchTitleLDASim', 'searchDescLDASim', \\\n",
    "                                     round('relevance').alias('label')).cache()\n",
    "\n",
    "optimalClsPredictions = optimalClsPipeline.fit(trDF).transform(testReadyDF)\n",
    "\n",
    "optimalClsPredict = optimalClsPredictions.withColumn('predict', round('prediction')).select('id', 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 166693 prediction results to db\n"
     ]
    }
   ],
   "source": [
    "def formatRow(row):\n",
    "    ret = {}\n",
    "    ret['title'] = 'optimal_classification'\n",
    "    ret['id'] = int(row[0])\n",
    "    ret['predict'] = int(row[1])\n",
    "    return ret\n",
    "    \n",
    "l = optimalClsPredict.rdd.map(list).collect()\n",
    "formattedResult = map(formatRow, l)\n",
    "\n",
    "# save prediction result\n",
    "result = outputCollection.insert_many(formattedResult)\n",
    "\n",
    "print \"Inserted %d prediction results to db\" %len(result.inserted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](score.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
